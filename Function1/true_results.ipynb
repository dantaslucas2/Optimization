{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def f(x):\n",
    "    return -np.exp(-x[0]**2 - x[1]**2 - 0.5*x[2]**2 - 0.1*x[3]**4 - (x[4]-1)**2)\n",
    "\n",
    "# x0 = [9,9,9,9,9]\n",
    "# x0 = [0,0,0,0,0.5]\n",
    "x0 = [1,1,1,1,0]\n",
    "# x0 = np.zeros(5)\n",
    "\n",
    "iteration_data = []\n",
    "\n",
    "def callback(xk):\n",
    "    iteration_data.append((len(iteration_data)+1, xk.copy(), f(xk)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Jacobian is required for Newton-CG method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-efe16f823971>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# for it, xk, fk in iteration_data:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         return _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m--> 621\u001b[0;31m                                   **options)\n\u001b[0m\u001b[1;32m    622\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_newtoncg\u001b[0;34m(fun, x0, args, jac, hess, hessp, callback, xtol, eps, maxiter, disp, return_all, **unknown_options)\u001b[0m\n\u001b[1;32m   1772\u001b[0m     \u001b[0m_check_unknown_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munknown_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1774\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Jacobian is required for Newton-CG method'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1775\u001b[0m     \u001b[0mfhess_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhessp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1776\u001b[0m     \u001b[0mfhess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Jacobian is required for Newton-CG method"
     ]
    }
   ],
   "source": [
    "xt = [[0,0,0,0,0], [0,0.2,0,0.3,0], [0.1,0,0.3,0,0], [0,0,-0.4,0,-0.1], [0,-0.2,0,0.2,0.3]]\n",
    "\n",
    "method = 'Newton-CG'\n",
    "\n",
    "for x0 in xt:\n",
    "    res = minimize(f, x0, method=method, callback=callback)\n",
    "\n",
    "    # for it, xk, fk in iteration_data:\n",
    "        # print(f'Iteração: {it} | Ponto atual: {xk} | Valor da função: {fk:.5f}\\n')\n",
    "        # print(f'Ponto atual: {xk}')\n",
    "        # print(f'Valor da função: {fk}\\n')\n",
    "    # Calcular o erro de aproximação final\n",
    "    if len(iteration_data) > 1:\n",
    "        _, _, fk_last = iteration_data[-1]\n",
    "        _, _, fk_second_last = iteration_data[-2]\n",
    "        final_approximation_error = abs(fk_last - fk_second_last)\n",
    "    else:\n",
    "        final_approximation_error = None\n",
    "    # Imprimir resultados detalhados em uma célula separada\n",
    "    print(x0)\n",
    "    print('Algoritmo utilizado:', method)\n",
    "    print('Ponto de mínimo:', res.x)\n",
    "    print('Valor da função no mínimo:', res.fun)\n",
    "    print('Número de iterações:', res.nit)\n",
    "    print('Erro de aproximação final:', final_approximation_error)\n",
    "    print('Número de avaliações da função:', res.nfev)\n",
    "    print('Sucesso da otimização:', res.success)\n",
    "    print('Mensagem de saída:', res.message)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algoritmo utilizado: CG\n",
      "Ponto de mínimo: [-4.53051269e-07 -4.53051269e-07 -1.14230562e-06  1.91766087e-02\n",
      "  1.00000045e+00]\n",
      "Valor da função no mínimo: -0.9999999864752915\n",
      "Número de iterações: 22\n",
      "Número de avaliações da função: 252\n",
      "Sucesso da otimização: True\n",
      "Mensagem de saída: Optimization terminated successfully.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quase-Newton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algoritmo utilizado: BFGS\n",
      "Ponto de mínimo: [-4.03612626e-09 -4.03612626e-09  7.84421882e-07  0.00000000e+00\n",
      "  9.99999782e-01]\n",
      "Valor da função no mínimo: -0.999999999999645\n",
      "Número de iterações: 5\n",
      "Erro de aproximação final: 2.336150795034797e-08\n",
      "Número de avaliações da função: 54\n",
      "Sucesso da otimização: True\n",
      "Mensagem de saída: Optimization terminated successfully.\n",
      "-------------\n",
      "Algoritmo utilizado: BFGS\n",
      "Ponto de mínimo: [-7.45601051e-09 -9.33162295e-07 -6.41422260e-09  6.63005895e-03\n",
      "  1.00000155e+00]\n",
      "Valor da função no mínimo: -0.9999999998035085\n",
      "Número de iterações: 16\n",
      "Erro de aproximação final: 5.148355075590416e-10\n",
      "Número de avaliações da função: 108\n",
      "Sucesso da otimização: True\n",
      "Mensagem de saída: Optimization terminated successfully.\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "method = 'BFGS'\n",
    "xt = [ [0,0,-0.4,0,-0.1], [0,-0.2,0,0.2,0.3]]\n",
    "\n",
    "for x0 in xt:\n",
    "    res = minimize(f, x0, method=method, callback=callback)\n",
    "\n",
    "    # for it, xk, fk in iteration_data:\n",
    "    #     print(f'Iteração: {it}')\n",
    "    #     print(f'Ponto atual: {xk}')\n",
    "    #     print(f'Valor da função: {fk}\\n')\n",
    "    if len(iteration_data) > 1:\n",
    "        _, _, fk_last = iteration_data[-1]\n",
    "        _, _, fk_second_last = iteration_data[-2]\n",
    "        final_approximation_error = abs(fk_last - fk_second_last)\n",
    "    else:\n",
    "        final_approximation_error = None\n",
    "    # Imprimir resultados detalhados em uma célula separada\n",
    "    print('Algoritmo utilizado:', method)\n",
    "    print('Ponto de mínimo:', res.x)\n",
    "    print('Valor da função no mínimo:', res.fun)\n",
    "    print('Número de iterações:', res.nit)\n",
    "    print('Erro de aproximação final:', final_approximation_error)\n",
    "    print('Número de avaliações da função:', res.nfev)\n",
    "    print('Sucesso da otimização:', res.success)\n",
    "    print('Mensagem de saída:', res.message)\n",
    "    print(\"-------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algoritmo utilizado: trust-constr\n",
      "Ponto de mínimo: [ 0.   0.  -0.4  0.  -0.1]\n",
      "Valor da função no mínimo: -0.2752707830897523\n",
      "Número de iterações: 28\n",
      "Erro de aproximação final: 0.0\n",
      "Número de avaliações da função: 28\n",
      "Sucesso da otimização: True\n",
      "Mensagem de saída: `xtol` termination condition is satisfied.\n",
      "-------------\n",
      "Algoritmo utilizado: trust-constr\n",
      "Ponto de mínimo: [ 0.  -0.2  0.   0.2  0.3]\n",
      "Valor da função no mínimo: -0.5885108004169485\n",
      "Número de iterações: 28\n",
      "Erro de aproximação final: 0.0\n",
      "Número de avaliações da função: 28\n",
      "Sucesso da otimização: True\n",
      "Mensagem de saída: `xtol` termination condition is satisfied.\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Define a função objetivo\n",
    "def f(x):\n",
    "    return -np.exp(-x[0]**2 - x[1]**2 - 0.5*x[2]**2 - 0.1*x[3]**4 - (x[4]-1)**2)\n",
    "\n",
    "# Define a Jacobiana da função objetivo\n",
    "def jac_f(x):\n",
    "    df_dx0 = 2 * x[0] * np.exp(-x[0]**2 - x[1]**2 - 0.5*x[2]**2 - 0.1*x[3]**4 - (x[4]-1)**2)\n",
    "    df_dx1 = 2 * x[1] * np.exp(-x[0]**2 - x[1]**2 - 0.5*x[2]**2 - 0.1*x[3]**4 - (x[4]-1)**2)\n",
    "    df_dx2 = x[2] * np.exp(-x[0]**2 - x[1]**2 - 0.5*x[2]**2 - 0.1*x[3]**4 - (x[4]-1)**2)\n",
    "    df_dx3 = -0.4 * x[3]**3 * np.exp(-x[0]**2 - x[1]**2 - 0.5*x[2]**2 - 0.1*x[3]**4 - (x[4]-1)**2)\n",
    "    df_dx4 = -2 * (x[4]-1) * np.exp(-x[0]**2 - x[1]**2 - 0.5*x[2]**2 - 0.1*x[3]**4 - (x[4]-1)**2)\n",
    "    return np.array([df_dx0, df_dx1, df_dx2, df_dx3, df_dx4])\n",
    "\n",
    "# Chute inicial\n",
    "xt = [ [0,0,-0.4,0,-0.1], [0,-0.2,0,0.2,0.3]]\n",
    "\n",
    "# Lista para armazenar as informações de cada iteração\n",
    "iteration_data = []\n",
    "\n",
    "# Função callback que será chamada a cada iteração\n",
    "def callback(xk, state):\n",
    "    iteration_data.append((len(iteration_data) + 1, xk.copy(), f(xk)))\n",
    "\n",
    "# Método utilizado\n",
    "method = 'trust-constr'\n",
    "\n",
    "# Execução para cada chute inicial\n",
    "for x0 in xt:\n",
    "    res = minimize(f, x0, method=method, jac=jac_f, hess='2-point', callback=callback)\n",
    "\n",
    "    # Cálculo do erro de aproximação final\n",
    "    if len(iteration_data) > 1:\n",
    "        _, _, fk_last = iteration_data[-1]\n",
    "        _, _, fk_second_last = iteration_data[-2]\n",
    "        final_approximation_error = abs(fk_last - fk_second_last)\n",
    "    else:\n",
    "        final_approximation_error = None\n",
    "    \n",
    "    # Imprimir resultados detalhados em uma célula separada\n",
    "    print('Algoritmo utilizado:', method)\n",
    "    print('Ponto de mínimo:', res.x)\n",
    "    print('Valor da função no mínimo:', res.fun)\n",
    "    print('Número de iterações:', res.nit)\n",
    "    print('Erro de aproximação final:', final_approximation_error)\n",
    "    print('Número de avaliações da função:', res.nfev)\n",
    "    print('Sucesso da otimização:', res.success)\n",
    "    print('Mensagem de saída:', res.message)\n",
    "    print(\"-------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algoritmo utilizado: BFGS\n",
      "Ponto de mínimo: [1.66795189e-06 1.66795189e-06 2.74981721e-08 9.88020595e-03\n",
      " 1.00000340e+00]\n",
      "Valor da função no mínimo: -0.9999999990299144\n",
      "Número de iterações: 19\n",
      "Número de avaliações da função: 156\n",
      "Sucesso da otimização: True\n",
      "Mensagem de saída: Optimization terminated successfully.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, -0.2, 0, 0.2, 0.3]\n",
      "Algoritmo utilizado: Newton-CG\n",
      "Ponto de mínimo: [ 0.  -0.2  0.   0.2  0.3]\n",
      "Valor da função no mínimo: -0.5885108004169485\n",
      "Número de iterações: 0\n",
      "Erro de aproximação final: 1.3427736700322157e-10\n",
      "Número de avaliações da função: 1\n",
      "Sucesso da otimização: False\n",
      "Mensagem de saída: Warning: CG iterations didn't converge. The Hessian is not positive definite.\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "def jac_f(x):\n",
    "    # Calcula as derivadas parciais da função objetivo em relação a cada variável\n",
    "    df_dx0 = 2 * x[0] * np.exp(-x[0]**2 - x[1]**2 - 0.5*x[2]**2 - 0.1*x[3]**4 - (x[4]-1)**2)\n",
    "    df_dx1 = 2 * x[1] * np.exp(-x[0]**2 - x[1]**2 - 0.5*x[2]**2 - 0.1*x[3]**4 - (x[4]-1)**2)\n",
    "    df_dx2 = x[2] * np.exp(-x[0]**2 - x[1]**2 - 0.5*x[2]**2 - 0.1*x[3]**4 - (x[4]-1)**2)\n",
    "    df_dx3 = -0.4 * x[3]**3 * np.exp(-x[0]**2 - x[1]**2 - 0.5*x[2]**2 - 0.1*x[3]**4 - (x[4]-1)**2)\n",
    "    df_dx4 = -2 * (x[4]-1) * np.exp(-x[0]**2 - x[1]**2 - 0.5*x[2]**2 - 0.1*x[3]**4 - (x[4]-1)**2)\n",
    "    \n",
    "    # Retorna a Jacobiana como um vetor\n",
    "    return np.array([df_dx0, df_dx1, df_dx2, df_dx3, df_dx4])\n",
    "\n",
    "# Escolha do algoritmo de otimização (Newton-CG)\n",
    "method = 'Newton-CG'\n",
    "\n",
    "# Minimização da função\n",
    "\n",
    "xt = [[0,0,0,0,0], [0,0.2,0,0.3,0], [0.1,0,0.3,0,0], [0,0,-0.4,0,-0.1], [0,-0.2,0,0.2,0.3]]\n",
    "for x0 in xt:\n",
    "    res = minimize(f, x0, method=method, jac=jac_f, callback=callback)\n",
    "\n",
    "    # for it, xk, fk in iteration_data:\n",
    "        # print(f'Iteração: {it} | Ponto atual: {xk} | Valor da função: {fk:.5f}\\n')\n",
    "        # print(f'Ponto atual: {xk}')\n",
    "        # print(f'Valor da função: {fk}\\n')\n",
    "    # Calcular o erro de aproximação final\n",
    "    if len(iteration_data) > 1:\n",
    "        _, _, fk_last = iteration_data[-1]\n",
    "        _, _, fk_second_last = iteration_data[-2]\n",
    "        final_approximation_error = abs(fk_last - fk_second_last)\n",
    "    else:\n",
    "        final_approximation_error = None\n",
    "    # Imprimir resultados detalhados em uma célula separada\n",
    "    print(x0)\n",
    "    print('Algoritmo utilizado:', method)\n",
    "    print('Ponto de mínimo:', res.x)\n",
    "    print('Valor da função no mínimo:', res.fun)\n",
    "    print('Número de iterações:', res.nit)\n",
    "    print('Erro de aproximação final:', final_approximation_error)\n",
    "    print('Número de avaliações da função:', res.nfev)\n",
    "    print('Sucesso da otimização:', res.success)\n",
    "    print('Mensagem de saída:', res.message)\n",
    "    print(\"---------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir resultados detalhados em uma célula separada\n",
    "print('Algoritmo utilizado:', method)\n",
    "print('Ponto de mínimo:', res.x)\n",
    "print('Valor da função no mínimo:', res.fun)\n",
    "print('Número de iterações:', res.nit)\n",
    "print('Número de avaliações da função:', res.nfev)\n",
    "print('Sucesso da otimização:', res.success)\n",
    "print('Mensagem de saída:', res.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testando valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9991903279614445"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f([0,0,0,0.3,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
